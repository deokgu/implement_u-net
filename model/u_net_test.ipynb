{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class u_net(nn.Module):\n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "            It consists of the repeated application of two 3x3 convolutions (unpadded convolutions),\n",
    "            each followed by a rectified linear unit (ReLU) \n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dconv_down1 = self.double_conv(3, 64) \n",
    "        self.maxpool_2x2 = nn.MaxPool2d(kernel_size= 2, stride=2) # 2x2 max pooling operation with stride 2 for downsampling. At each downsampling step we double the number of feature channels\n",
    "\n",
    "        self.dconv_down2 = self.double_conv(64, 128)\n",
    "        self.maxpool_2x2 = nn.MaxPool2d(kernel_size =2, stride=2)\n",
    "\n",
    "        self.dconv_down3 = self.double_conv(128, 256)\n",
    "        self.maxpool_2x2 = nn.MaxPool2d(kernel_size =2, stride=2)\n",
    "\n",
    "        self.dconv_down4= self.double_conv(256, 512)\n",
    "        self.maxpool_2x2 = nn.MaxPool2d(kernel_size =2, stride=2)\n",
    "\n",
    "        self.dconv_down5 = self.double_conv(512, 1024)\n",
    "\n",
    "        self.up_trans_1 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n",
    "        self.up_conv_1 = self.double_conv(1024,512)\n",
    "        \n",
    "        self.up_trans_2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
    "        self.up_conv_2 = self.double_conv(1024,512)\n",
    "        \n",
    "        self.up_trans_3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
    "        self.up_conv_3 = self.double_conv(1024,512)\n",
    "\n",
    "        self.up_trans_4 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
    "        self.up_conv_4 = self.double_conv(1024,512)\n",
    "\n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1) # 1x1 convolution\n",
    "u_net()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'ConvTransposed'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8c4dc1eab80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_trans_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvTransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mu_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-8c4dc1eab80a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdconv_down5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_trans_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvTransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mu_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'ConvTransposed'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}